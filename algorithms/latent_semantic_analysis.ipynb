{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![MSE Logo](https://moodle.msengineering.ch/pluginfile.php/1/core_admin/logocompact/300x300/1613732714/logo-mse.png \"MSE Logo\") \n",
    "\n",
    "# Latent Semantic Analysis with Gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os    \n",
    "import nltk\n",
    "import gensim\n",
    "import pandas as pd\n",
    "from TextPreprocessor import *\n",
    "from gensim import models, corpora, similarities\n",
    "from gensim.models import LsiModel, LdaModel, LdaMulticore\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../rss/content_daily.json\") as f:\n",
    "    content = json.load(f)\n",
    "\n",
    "text = list(content.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.DataFrame({'text': text})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing\n",
    "\n",
    "You will need first to preprocess the data through the following stages:\n",
    "1. tokenization\n",
    "2. stopword removal\n",
    "2. POS-based filtering (optional)\n",
    "3. lemmatization or stemming (optional)\n",
    "4. addition of bigrams to each document (optional)\n",
    "5. filtering of infrequent words\n",
    "6. inspection and filtering of frequent words\n",
    "\n",
    "You can use NLTK or our in-house `TextPreprocessor.py` file, as explained in Lab 1.\n",
    "\n",
    "<font color='green'>Please state here which solution you use and list stages you implement.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANSWER**\n",
    "\n",
    "We used:\n",
    "- tokenization\n",
    "- removing of stopwords\n",
    "- low frequency words removal\n",
    "\n",
    "We finally inspected and filtered the frequent words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please write here the preprocessing instructions if you use TextPreprocessor.py\n",
    "\n",
    "language = 'english'\n",
    "stop_words = set(stopwords.words(language))\n",
    "# Extend the list here:\n",
    "for custom_sw in ['\\\"', '\\'', '\\'\\'', '`', '``', '\\'s']:\n",
    "    stop_words.add(custom_sw)\n",
    "\n",
    "processor = TextPreprocessor(\n",
    "    language = language,\n",
    "    pos_tags = {wordnet.ADJ, wordnet.NOUN},\n",
    "    stopwords = stop_words,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['processed'] = processor.transform(data_df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['tokenized'] = data_df['processed'].apply(nltk.word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternatively, please write here the preprocessing instructions if you use NLTK\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['whether', 'rickety', 'ramp', 'air', 'wheelies', 'ultimate', 'buzz', 'thrill-seekers', '1980s', 'young', 'bmx', 'rider', 'jumped', 'trendy', 'new', 'bike', 'friend', 'relation', 'brave', 'lie', 'ground', 'beneath', 'bonfire', 'zero', 'dry', 'land', 'pier', 'sea', 'photo', 'heady', 'day', 'show', 'new', 'book', 'story', 'bmx', 'stand', 'bicycle', 'motocross', 'craze', '1980s', 'bike', 'must-have', 'garden', 'park', 'without', 'rider', 'delighted', 'manner', 'stunt', 'off-road', 'shenanigan', 'whole', 'hog', 'helmet', 'fancy', 'suit', 'pre-health', 'safety', 'day', 'many', 'much', 'fun', 'bother', 'course', 'olympic', 'sport', 'one', 'beth', 'shriever', 'gold', 'kye', 'whyte', 'silver', 'tokyo', 'olympics', 'last', 'year', 'book', 'three', 'co-authors', 'old', 'day', 'thrill', 'spill', 'special', 'place', 'heart', 'antony', 'frascina', 'infant', 'school', 'teacher', 'wigan', \"'in\", '80', 'bmx', 'like', 'bolt', 'life', 'shiny', 'chrome', 'new', 'aspirational', 'dangerous', 'scary', 'half', 'fun', 'like', 'love', 'leaf', 'friend', 'fellow', 'bmx', 'fan', 'andrew', 'rigby', 'intensive', 'care', 'nurse', 'liverpool', 'clint', 'pilkington', 'solution', 'architect', 'manchester', 'spent', 'three', 'year', 'hundred', 'nostalgic', 'photo', 'anecdote', 'glorious', 'era', 'book', 'rad', \"'rad\", 'short', 'radical', 'bmx-ers', 'slang', 'cool', 'high', 'faster', 'anyone', 'trio', 'well-known', 'bmx', 'show', 'prize', 'building', \"'old\", 'school', 'bike', 'book', 'focus', 'everyday', 'rider', '1980s', 'antony', 'put', 'endless', 'summer', 'freedom', 'bike', 'day', 'street', 'light', 'night', 'time', 'home', 'clint', 'bmx', 'present', 'one', 'christmas', \"'more\", 'new', 'set', 'tyre', 'key', 'palace', 'gateway', 'freedom', 'door', 'narnia', 'thing', 'andrew', 'emergence', 'growth', 'bmx', 'u', 'ability', 'gain', 'degree', 'independence', 'freedom', 'young', 'age', 'met', 'new', 'people', 'different', 'age', 'background', 'bmx', 'united', 'u', 'magical', 'year', 'bmx', 'meant', 'everything', 'rad', 'ps45', 'available', 'via']\n"
     ]
    }
   ],
   "source": [
    "print(data_df['tokenized'].iloc[120])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please make a list of all words from all articles.  Then, using `nltk.FreqDist`, consider the most frequent and the least frequent words.  If you find uninformative words among the most frequent ones, please remove them from the articles.  Similarly, please remove from articles the words appearing fewer than 2 or 3 times in the corpus.  <font color='green'> Please justify these choices. What is now the size of your vocabulary?</font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANSWER**\n",
    "\n",
    "We removed the words appearing only 2-3 times because they won't be relevant for the further analysis: they do not carry much informations, and are not frequent enough to be associated with other words.\n",
    "Some small words are removed to, independantly from their frequency (like \"u\", \"two\", \"mr\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_to_filter = [\"u\",\"two\",\"could\",\"mr\",\"one\", \"per\", \"cent\",\"hrt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary length: 10204\n",
      "Number of filtered words: 2716\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>processed</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>filtered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A fearless badger is harassing passers-by at a...</td>\n",
       "      <td>fearless badger passer-by beauty spot -- rspca...</td>\n",
       "      <td>[fearless, badger, passer-by, beauty, spot, --...</td>\n",
       "      <td>[fearless, badger, passer-by, beauty, spot, --...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Only disabled actors should play Richard III, ...</td>\n",
       "      <td>disabled actor play richard iii head royal sha...</td>\n",
       "      <td>[disabled, actor, play, richard, iii, head, ro...</td>\n",
       "      <td>[disabled, actor, play, richard, iii, head, ro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sir Keir Starmer's Labour have seized control ...</td>\n",
       "      <td>sir keir starmer labour control tory stronghol...</td>\n",
       "      <td>[sir, keir, starmer, labour, control, tory, st...</td>\n",
       "      <td>[sir, keir, starmer, labour, control, tory, st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Labour will be 'somewhat disappointed' by thei...</td>\n",
       "      <td>labour 'somewhat disappointed local election r...</td>\n",
       "      <td>[labour, 'somewhat, disappointed, local, elect...</td>\n",
       "      <td>[labour, 'somewhat, disappointed, local, elect...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Follow MailOnline's live coverage for all the ...</td>\n",
       "      <td>mailonline live coverage update local election...</td>\n",
       "      <td>[mailonline, live, coverage, update, local, el...</td>\n",
       "      <td>[mailonline, live, coverage, update, local, el...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  A fearless badger is harassing passers-by at a...   \n",
       "1  Only disabled actors should play Richard III, ...   \n",
       "2  Sir Keir Starmer's Labour have seized control ...   \n",
       "3  Labour will be 'somewhat disappointed' by thei...   \n",
       "4  Follow MailOnline's live coverage for all the ...   \n",
       "\n",
       "                                           processed  \\\n",
       "0  fearless badger passer-by beauty spot -- rspca...   \n",
       "1  disabled actor play richard iii head royal sha...   \n",
       "2  sir keir starmer labour control tory stronghol...   \n",
       "3  labour 'somewhat disappointed local election r...   \n",
       "4  mailonline live coverage update local election...   \n",
       "\n",
       "                                           tokenized  \\\n",
       "0  [fearless, badger, passer-by, beauty, spot, --...   \n",
       "1  [disabled, actor, play, richard, iii, head, ro...   \n",
       "2  [sir, keir, starmer, labour, control, tory, st...   \n",
       "3  [labour, 'somewhat, disappointed, local, elect...   \n",
       "4  [mailonline, live, coverage, update, local, el...   \n",
       "\n",
       "                                            filtered  \n",
       "0  [fearless, badger, passer-by, beauty, spot, --...  \n",
       "1  [disabled, actor, play, richard, iii, head, ro...  \n",
       "2  [sir, keir, starmer, labour, control, tory, st...  \n",
       "3  [labour, 'somewhat, disappointed, local, elect...  \n",
       "4  [mailonline, live, coverage, update, local, el...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Please write here all the necessary instructions.  You may use several cells.\n",
    "vocabulary = data_df['tokenized'].sum()\n",
    "\n",
    "most_common = [word for word, freq in nltk.FreqDist(vocabulary).items() if freq > 4 and word not in words_to_filter]\n",
    "\n",
    "data_df['filtered']=data_df['tokenized']\n",
    "\n",
    "voc_size_filtered=0\n",
    "voc_size_tokenized=0\n",
    "\n",
    "for del_words in words_to_filter:\n",
    "    for data in data_df['filtered']:\n",
    "        if del_words in data:\n",
    "            data.remove(del_words)\n",
    "\n",
    "print(f\"Vocabulary length: {len(nltk.FreqDist(vocabulary))}\")\n",
    "print(f\"Number of filtered words: {len(most_common)}\")\n",
    "\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['brother', 'itv', 'reality', 'show', \"'life\", 'marbs', 'pr', 'bos', 'exclusive', 'mayfair', 'club', 'woman', 'private', 'booth', 'court', 'heard', 'old', 'harrovian', 'adam', 'graham', 'brother', 'jeffrey', 'member', 'public', 'private', 'area', 'celebrity', 'haunt', 'pair', 'area', 'maddox', 'club', 'count', 'prince', 'harry', 'among', 'past', 'famous', 'guest', 'friend', 'family', 'uninvited', 'guest', 'party', 'tom', 'heslop', 'told', 'westminster', 'magistrate', 'court', \"'the\", 'defendant', 'annoyed', 'member', 'public', 'space', 'pair', 'set', 'new', 'luxury', 'concierge', 'business', 'twelve-episode', 'reality', 'series', 'life', 'marbs', 'life', 'glamorous', 'resident', 'living', 'popular', 'spanish', 'resort', '2015.', 'heslop', 'victim', 'pr', 'manager', 'jacob', 'bohbot', 'sat', 'table', 'group', 'woman', 'graham', 'family', 'brother', 'thought', 'woman', 'space', 'security', 'area', 'court', 'heard', 'adam', 'claimed', 'ushered', 'woman', 'kept', 'area', 'bohbot', 'jeffrey', 'treatment', 'jeffrey', 'struck', 'bohbot', 'face', \"'the\", 'victim', 'felt', 'multiple', 'hand', 'hit', 'mr', 'bohbot', \"'the\", 'victim', 'time', 'uncertain', 'jeffrey', 'adam', 'cctv', 'jeffrey', 'graham', 'begin', 'assault', 'adam', 'join', 'george', 'dugbo', \"'they\", 'club', 'family', 'event', \"'they\", 'private', 'area', 'female', 'member', 'public', 'personal', 'space', \"'they\", 'security', 'guard', 'number', 'time', 'adam', 'ushered', 'female', 'member', 'public', 'mr', 'dugbo', \"'spur\", 'moment', 'emotional', 'reaction', 'jeffrey', 'adam', 'protect', 'brother', 'brother', \"'letter\", 'apology', 'step', 'complainant', 'pair', 'set', 'new', 'luxury', 'concierge', 'business', 'court', 'heard', 'magistrate', 'claire', 'harris', \"'this\", 'would', 'incident', 'victim', 'people', 'night', \"'this\", 'serious', 'incident', 'four', 'type', 'injury', 'hear', 'chipped', 'tooth', 'injury', 'time', \"'we\", 'account', 'good', 'character', 'remorse', 'hope', 'court', 'graham', 'brother', 'willow', 'park', 'way', 'aston-on-trent', 'near', 'derby', 'assault', 'beating', 'adam', 'graham', '12-month', 'community', 'order', 'hour', 'unpaid', 'work', 'whilst', 'jeffrey', 'graham', '12-month', 'community', 'order', 'hour', 'unpaid', 'work', 'brother', 'pay', 'ps100', 'compensation', 'victim', 'ps180', 'court', 'cost', 'fee', 'maddox', 'club', 'duration', 'community', 'order', 'prince', 'harry', 'sophie', 'elli', 'bextor', 'keira', 'diddy', 'cesc', 'fabregas', 'pharell', 'williams', 'ps450-a-year', 'member', 'club', 'near', 'savile', 'row']\n"
     ]
    }
   ],
   "source": [
    "print(data_df['filtered'].iloc[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSA with Gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, you will write the Gensim commands to compute a term-document matrix from the above documents, then transform it using SVD, and truncate the result.  To learn what the commands are, please follow the [Topics and Tranformations tutorial](https://radimrehurek.com/gensim/auto_examples/core/run_topics_and_transformations.html) from Gensim. \n",
    "\n",
    "<font color=\"green\">Please gather these commands into a function called `train_lsa`.  They should cover: dictionary creation, corpus mapping, computation of TF-IDF values, and creation of the LSA model.</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lsa(filtered_texts, num_topics = 10):\n",
    "    dictionary = corpora.Dictionary(filtered_texts)\n",
    "    corpus = [dictionary.doc2bow(text) for text in filtered_texts]\n",
    "\n",
    "    # transform the vectors to tf-idf representation\n",
    "    tfidf = models.TfidfModel(corpus)\n",
    "    corpus_tfidf = tfidf[corpus]\n",
    "\n",
    "    lsa = models.LsiModel(corpus_tfidf, id2word=dictionary, num_topics=num_topics)\n",
    "    corpus_tfidf = lsa[corpus_tfidf]\n",
    "\n",
    "    return lsa,dictionary,corpus,corpus_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"green\">Please fix a `number_of_topics`, on the lower side of the range mentioned in the course.  Then, execute the cell that performs `train_lsa`.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_topics = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsa_model, dictionary, corpus, corpus_tfidf = train_lsa(data_df['filtered'], number_of_topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"green\">Please display several topics found by LSA using the Gensim `print_topics` function.  Please explain in your own words the meaning of what is displayed.  How do you relate it with what was explained in the course on LSA?</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANSWER**\n",
    "\n",
    "`print_topics` returns the `n` (50 in our case) most relevant topics. Each topic consist of a list of words associated with a relevancy score. The higher the score the more relevant is the word according to the topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '-0.156*\"abortion\" + -0.153*\"ukraine\" + -0.144*\"russian\" + -0.135*\"cent\" + -0.126*\"per\" + -0.124*\"russia\" + -0.117*\"labour\" + -0.115*\"mr\" + -0.106*\"keir\" + -0.103*\"mp\"'),\n",
       " (1,\n",
       "  '-0.566*\"abortion\" + -0.321*\"roe\" + -0.206*\"court\" + -0.195*\"supreme\" + -0.182*\"wade\" + -0.162*\"v.\" + -0.161*\"draft\" + -0.125*\"opinion\" + -0.124*\"justice\" + -0.112*\"state\"'),\n",
       " (2,\n",
       "  '-0.285*\"russian\" + 0.282*\"cent\" + -0.277*\"ukraine\" + 0.251*\"per\" + 0.237*\"rate\" + -0.232*\"russia\" + -0.188*\"putin\" + -0.173*\"ukrainian\" + 0.154*\"repayment\" + -0.124*\"war\"'),\n",
       " (3,\n",
       "  '-0.266*\"keir\" + 0.246*\"cent\" + 0.242*\"rate\" + -0.230*\"sir\" + -0.225*\"labour\" + 0.215*\"per\" + -0.204*\"rayner\" + -0.194*\"mp\" + -0.167*\"durham\" + 0.163*\"repayment\"'),\n",
       " (4,\n",
       "  '-0.212*\"keir\" + -0.175*\"sir\" + -0.173*\"labour\" + 0.147*\"police\" + -0.143*\"abortion\" + -0.138*\"ukraine\" + -0.137*\"rayner\" + -0.135*\"russian\" + -0.122*\"cent\" + -0.121*\"durham\"'),\n",
       " (5,\n",
       "  '0.402*\"labor\" + 0.349*\"albanese\" + 0.199*\"clare\" + 0.197*\"mr\" + -0.172*\"rate\" + -0.153*\"repayment\" + -0.152*\"police\" + 0.151*\"morrison\" + 0.134*\"scheme\" + 0.103*\"equity\"'),\n",
       " (6,\n",
       "  '0.479*\"musk\" + 0.304*\"twitter\" + -0.188*\"police\" + 0.171*\"biden\" + -0.128*\"labor\" + 0.127*\"billion\" + 0.125*\"noah\" + 0.120*\"trump\" + -0.114*\"albanese\" + 0.112*\"tesla\"'),\n",
       " (7,\n",
       "  '0.208*\"police\" + 0.207*\"musk\" + -0.199*\"queen\" + -0.188*\"mp\" + -0.184*\"migrant\" + 0.163*\"keir\" + -0.148*\"royal\" + 0.146*\"durham\" + 0.136*\"twitter\" + -0.128*\"duke\"'),\n",
       " (8,\n",
       "  '-0.289*\"mp\" + 0.236*\"queen\" + 0.195*\"keir\" + 0.173*\"royal\" + 0.160*\"duke\" + 0.158*\"prince\" + -0.151*\"common\" + 0.146*\"durham\" + -0.142*\"whip\" + -0.125*\"rayner\"'),\n",
       " (9,\n",
       "  '0.307*\"migrant\" + 0.200*\"rwanda\" + -0.173*\"chyna\" + -0.158*\"queen\" + 0.153*\"asylum\" + 0.130*\"flight\" + 0.130*\"uk\" + 0.123*\"boat\" + 0.121*\"hrt\" + -0.120*\"noah\"')]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsa_model.print_topics(number_of_topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"green\">Please define a function that returns the cosine similarity between two words (testing first if they are in the vocabulary). Please exemplify its value on two different word pairs, one of which should be obviously more similar than the other, and comment the values.</font>  You can get inspiration from this [Gensim Tutorial on Document Similarity](https://radimrehurek.com/gensim/auto_examples/core/run_similarity_queries.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordsim(word1, word2, model, dictionary):\n",
    "    vec_w1=dictionary.doc2bow(word1.lower().split())\n",
    "    vec_w2=dictionary.doc2bow(word2.lower().split())\n",
    "\n",
    "    #get words in lsa space\n",
    "    lsa_w1=model[vec_w1]\n",
    "    lsa_w2=model[vec_w2]\n",
    "\n",
    "    return cosine_similarity(lsa_w1,lsa_w2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First example\n",
      "[[ 1.00000000e+00 -1.95719097e-02  2.45908862e-03 ... -7.22326848e-05\n",
      "   2.00836082e-04 -9.84526698e-06]\n",
      " [-3.37170374e-02  9.99899887e-01  9.99345484e-01 ...  9.99433852e-01\n",
      "   9.99424627e-01  9.99431751e-01]\n",
      " [-1.11353343e-02  9.99964404e-01  9.99907594e-01 ...  9.99938802e-01\n",
      "   9.99935744e-01  9.99938110e-01]\n",
      " ...\n",
      " [ 3.11510785e-05  9.99807842e-01  9.99997053e-01 ...  9.99999995e-01\n",
      "   9.99999986e-01  9.99999999e-01]\n",
      " [-8.27244688e-05  9.99810067e-01  9.99996770e-01 ...  1.00000000e+00\n",
      "   9.99999960e-01  9.99999997e-01]\n",
      " [-1.08781777e-04  9.99810575e-01  9.99996703e-01 ...  9.99999999e-01\n",
      "   9.99999952e-01  9.99999995e-01]]\n",
      "Second example\n",
      "[[ 1.00000000e+00 -9.29780948e-02  8.56240775e-03 ...  1.12656676e-05\n",
      "  -3.26948146e-05 -9.27223800e-05]\n",
      " [-3.78559337e-02  9.98474239e-01  9.98922437e-01 ...  9.99282781e-01\n",
      "   9.99284444e-01  9.99286713e-01]\n",
      " [ 7.73324985e-03  9.94919359e-01  9.99999656e-01 ...  9.99970185e-01\n",
      "   9.99969845e-01  9.99969377e-01]\n",
      " ...\n",
      " [ 2.41747284e-05  9.95665906e-01  9.99963549e-01 ...  1.00000000e+00\n",
      "   9.99999998e-01  9.99999993e-01]\n",
      " [-2.01646364e-05  9.95670029e-01  9.99963169e-01 ...  1.00000000e+00\n",
      "   1.00000000e+00  9.99999997e-01]\n",
      " [-1.67533689e-04  9.95683717e-01  9.99961893e-01 ...  9.99999984e-01\n",
      "   9.99999991e-01  9.99999997e-01]]\n"
     ]
    }
   ],
   "source": [
    "# print here the cosine similiarities of several pairs and comment the results.\n",
    "print(\"First example\")\n",
    "print(wordsim(\"indian\",\"detention\",lsa_model,dictionary))\n",
    "\n",
    "#second example\n",
    "print(\"Second example\")\n",
    "print(wordsim(\"fire\",\"australia\",lsa_model,dictionary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"green\">Please use the [Gensim Tutorial on Document Similarity](https://radimrehurek.com/gensim/auto_examples/core/run_similarity_queries.html) to write a function that prints a list of words sorted by decreasing LSA similarity with a given word and showing the score too.  You don't have to use the cosine_similarity function here.  Please choose a \"query\" word and ten other words, apply your function, and comment the results.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_ranking(word0, word_list, model, dictionary):\n",
    "    # transform corpus to LSI space and index it\n",
    "    vec_w0=dictionary.doc2bow(word0.lower().split())\n",
    "    vec_w_list=[dictionary.doc2bow(text.lower().split()) for text in word_list]\n",
    "    index = similarities.MatrixSimilarity(model[vec_w_list])\n",
    "\n",
    "    #get word in lsa space\n",
    "    lsa_w0=model[vec_w0]\n",
    "\n",
    "    sims_w0 = index[lsa_w0]\n",
    "    sims = sorted(enumerate(sims_w0), key=lambda item: -item[1])\n",
    "    for doc_position, doc_score in sims:\n",
    "        print(doc_score, dictionary[doc_position])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.017094733 around\n",
      "0.01702085 blaze\n",
      "0.0 burn\n",
      "-0.0019819743 aedt\n",
      "-0.029712332 authority\n",
      "-0.037531205 bureau\n",
      "-0.06593551 blue\n",
      "-0.08245504 across\n",
      "-0.09509794 available\n",
      "-0.17063233 area\n"
     ]
    }
   ],
   "source": [
    "# call here the function on your choice of words\n",
    "word_list=[\"worker\",\"warn\",\"escalate\",\"industrial\",\"action\",\"company\",\"reject\",\"srinagar\",\"death\",\"come\"]\n",
    "word_ranking(\"industry\",word_list,lsa_model,dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please write here your comments on the rankings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANSWER**\n",
    "\n",
    "The ranking seams ok, but it is difficult to really to evaluate its quality as it really depends on the dictionnary used. Also the topic has to match more or less the words of the vocabulary, otherwise the scores would be all 0.0.\n",
    "\n",
    "Also if the topics are not well balanced, the ranking won't be good.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"green\">Please select now a significantly larger number of topics, and train a new LSA model.  Perform the same `word_ranking` task as above and compare the new ranking with the previous one.  Which one seems better?</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of Lab 5\n",
    "Please make sure all cells have been executed, save this completed notebook, compress it to a *zip* file, and upload it to [Moodle](https://moodle.msengineering.ch/course/view.php?id=1869)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>processed</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>filtered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A fearless badger is harassing passers-by at a...</td>\n",
       "      <td>fearless badger passer-by beauty spot -- rspca...</td>\n",
       "      <td>[fearless, badger, passer-by, beauty, spot, --...</td>\n",
       "      <td>[fearless, badger, passer-by, beauty, spot, --...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Only disabled actors should play Richard III, ...</td>\n",
       "      <td>disabled actor play richard iii head royal sha...</td>\n",
       "      <td>[disabled, actor, play, richard, iii, head, ro...</td>\n",
       "      <td>[disabled, actor, play, richard, iii, head, ro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sir Keir Starmer's Labour have seized control ...</td>\n",
       "      <td>sir keir starmer labour control tory stronghol...</td>\n",
       "      <td>[sir, keir, starmer, labour, control, tory, st...</td>\n",
       "      <td>[sir, keir, starmer, labour, control, tory, st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Labour will be 'somewhat disappointed' by thei...</td>\n",
       "      <td>labour 'somewhat disappointed local election r...</td>\n",
       "      <td>[labour, 'somewhat, disappointed, local, elect...</td>\n",
       "      <td>[labour, 'somewhat, disappointed, local, elect...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Follow MailOnline's live coverage for all the ...</td>\n",
       "      <td>mailonline live coverage update local election...</td>\n",
       "      <td>[mailonline, live, coverage, update, local, el...</td>\n",
       "      <td>[mailonline, live, coverage, update, local, el...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  A fearless badger is harassing passers-by at a...   \n",
       "1  Only disabled actors should play Richard III, ...   \n",
       "2  Sir Keir Starmer's Labour have seized control ...   \n",
       "3  Labour will be 'somewhat disappointed' by thei...   \n",
       "4  Follow MailOnline's live coverage for all the ...   \n",
       "\n",
       "                                           processed  \\\n",
       "0  fearless badger passer-by beauty spot -- rspca...   \n",
       "1  disabled actor play richard iii head royal sha...   \n",
       "2  sir keir starmer labour control tory stronghol...   \n",
       "3  labour 'somewhat disappointed local election r...   \n",
       "4  mailonline live coverage update local election...   \n",
       "\n",
       "                                           tokenized  \\\n",
       "0  [fearless, badger, passer-by, beauty, spot, --...   \n",
       "1  [disabled, actor, play, richard, iii, head, ro...   \n",
       "2  [sir, keir, starmer, labour, control, tory, st...   \n",
       "3  [labour, 'somewhat, disappointed, local, elect...   \n",
       "4  [mailonline, live, coverage, update, local, el...   \n",
       "\n",
       "                                            filtered  \n",
       "0  [fearless, badger, passer-by, beauty, spot, --...  \n",
       "1  [disabled, actor, play, richard, iii, head, ro...  \n",
       "2  [sir, keir, starmer, labour, control, tory, st...  \n",
       "3  [labour, 'somewhat, disappointed, local, elect...  \n",
       "4  [mailonline, live, coverage, update, local, el...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A fearless badger is harassing passers-by at a renowned beauty spot -- leading the RSPCA to warn the public about its behaviour. Dog walkers, joggers and families out enjoying the countryside have all fallen foul of the black and white menace. The badger has been recorded prowling during the day in Cannock Chase, Staffordshire, and following two barking dogs who were being pulled away by their owner. Despite the mammals' typical nocturnal habits, this particular individual has been seen taking leisurely strolls in broad daylight. It has run up towards barking dogs without flinching and chased a French bulldog, which sought refuge behind its owner. The RSPCA has warned the public to keep their distance from the badger and said its actions are not normal for the normally shy species. It is unusually approachable towards humans and followed one female jogger over stepping stones of a nearby stream, before getting bored and turning back. Ben Clay, 39, who filmed the badger while out walking with his children, said: 'Someone walked past and said 'Keep your dog on the lead as there is a badger wandering about'. 'I just kept an eye on the children and then looked up and saw it trotting down the path.' He captured the video and posted it on social media later on that day, writing: 'Little badger came out to play at stepping stones in Cannock Chase.' The video gained more than 370,000 views and almost 1,300 comments from viewers who were shocked and concerned for the animal. Harris Dickenson said: 'Might be worth a report to the RSPCA, that is not normal behaviour.' Victoria Hedges said: 'That's not a good thing. That's either a sick badger or one that someone has hand raised and released for some insane reason.' Another commenter, Oli Bonell said: 'It's most probably riddled with TB acting like that in broad daylight and looks thin to me.' With Kath Gebski adding: 'Poor thing, clearly something is wrong with him..'  'Did he think the little dog was related to him?' Newman Kelly questioned. With Christopher Johnson adding: 'Showing who is boss, pleased no one got too close.' It is understood that the badger is now receiving care. The nocturnal creatures are rarely seen in the day and live in large family groups in burrows under the ground, known as a sett. Cubs are born in January or February but spend the first few months underground, only coming out in spring when it is a little warmer. In a statement, the RSPCA said: 'This is not normal behaviour for a badger, who are nocturnal and wouldn't usually be seen in open daylight walking amongst people. 'The RSPCA would advise that if anyone sees this badger - or any other - behaving like this, to keep a distance, and to keep dogs well away. 'It may well be disoriented and could be unpredictable and aggressive. 'If you see a badger you have concerns about please call the RSPCA's emergency line on 0300 1234 999.'\n",
      "fearless badger passer-by beauty spot -- rspca warn public behaviour dog walker jogger family countryside foul black white menace badger day cannock chase staffordshire two barking dog owner despite mammal typical nocturnal habit particular individual stroll broad daylight towards barking dog without french bulldog sought refuge behind owner rspca public distance badger action normal shy specie approachable towards human one female jogger stone stream ben clay badger child 'someone past dog lead badger kept eye child saw path video social medium day 'little badger play stone cannock chase video 370,000 view 1,300 comment viewer concerned animal harris dickenson 'might worth report rspca normal behaviour victoria hedge 'that good thing either sick badger one someone hand insane reason another commenter oli bonell 'it tb like broad daylight look thin kath gebski 'poor thing something wrong .. 'did think little dog related newman christopher johnson bos pleased one understood badger care nocturnal creature day live large family group burrow ground sett cub born january february spend month underground spring little warmer statement rspca 'this normal behaviour badger nocturnal would open daylight amongst people 'the rspca would advise anyone see badger behaving like distance dog 'it may could unpredictable aggressive 'if badger concern please call rspca emergency line\n",
      "['fearless', 'badger', 'passer-by', 'beauty', 'spot', '--', 'rspca', 'warn', 'public', 'behaviour', 'dog', 'walker', 'jogger', 'family', 'countryside', 'foul', 'black', 'white', 'menace', 'badger', 'day', 'cannock', 'chase', 'staffordshire', 'barking', 'dog', 'owner', 'despite', 'mammal', 'typical', 'nocturnal', 'habit', 'particular', 'individual', 'stroll', 'broad', 'daylight', 'towards', 'barking', 'dog', 'without', 'french', 'bulldog', 'sought', 'refuge', 'behind', 'owner', 'rspca', 'public', 'distance', 'badger', 'action', 'normal', 'shy', 'specie', 'approachable', 'towards', 'human', 'female', 'jogger', 'stone', 'stream', 'ben', 'clay', 'badger', 'child', \"'someone\", 'past', 'dog', 'lead', 'badger', 'kept', 'eye', 'child', 'saw', 'path', 'video', 'social', 'medium', 'day', \"'little\", 'badger', 'play', 'stone', 'cannock', 'chase', 'video', '370,000', 'view', '1,300', 'comment', 'viewer', 'concerned', 'animal', 'harris', 'dickenson', \"'might\", 'worth', 'report', 'rspca', 'normal', 'behaviour', 'victoria', 'hedge', \"'that\", 'good', 'thing', 'either', 'sick', 'badger', 'one', 'someone', 'hand', 'insane', 'reason', 'another', 'commenter', 'oli', 'bonell', \"'it\", 'tb', 'like', 'broad', 'daylight', 'look', 'thin', 'kath', 'gebski', \"'poor\", 'thing', 'something', 'wrong', '..', \"'did\", 'think', 'little', 'dog', 'related', 'newman', 'christopher', 'johnson', 'bos', 'pleased', 'one', 'understood', 'badger', 'care', 'nocturnal', 'creature', 'day', 'live', 'large', 'family', 'group', 'burrow', 'ground', 'sett', 'cub', 'born', 'january', 'february', 'spend', 'month', 'underground', 'spring', 'little', 'warmer', 'statement', 'rspca', \"'this\", 'normal', 'behaviour', 'badger', 'nocturnal', 'would', 'open', 'daylight', 'amongst', 'people', \"'the\", 'rspca', 'would', 'advise', 'anyone', 'see', 'badger', 'behaving', 'like', 'distance', 'dog', \"'it\", 'may', 'unpredictable', 'aggressive', \"'if\", 'badger', 'concern', 'please', 'call', 'rspca', 'emergency', 'line']\n",
      "['fearless', 'badger', 'passer-by', 'beauty', 'spot', '--', 'rspca', 'warn', 'public', 'behaviour', 'dog', 'walker', 'jogger', 'family', 'countryside', 'foul', 'black', 'white', 'menace', 'badger', 'day', 'cannock', 'chase', 'staffordshire', 'barking', 'dog', 'owner', 'despite', 'mammal', 'typical', 'nocturnal', 'habit', 'particular', 'individual', 'stroll', 'broad', 'daylight', 'towards', 'barking', 'dog', 'without', 'french', 'bulldog', 'sought', 'refuge', 'behind', 'owner', 'rspca', 'public', 'distance', 'badger', 'action', 'normal', 'shy', 'specie', 'approachable', 'towards', 'human', 'female', 'jogger', 'stone', 'stream', 'ben', 'clay', 'badger', 'child', \"'someone\", 'past', 'dog', 'lead', 'badger', 'kept', 'eye', 'child', 'saw', 'path', 'video', 'social', 'medium', 'day', \"'little\", 'badger', 'play', 'stone', 'cannock', 'chase', 'video', '370,000', 'view', '1,300', 'comment', 'viewer', 'concerned', 'animal', 'harris', 'dickenson', \"'might\", 'worth', 'report', 'rspca', 'normal', 'behaviour', 'victoria', 'hedge', \"'that\", 'good', 'thing', 'either', 'sick', 'badger', 'one', 'someone', 'hand', 'insane', 'reason', 'another', 'commenter', 'oli', 'bonell', \"'it\", 'tb', 'like', 'broad', 'daylight', 'look', 'thin', 'kath', 'gebski', \"'poor\", 'thing', 'something', 'wrong', '..', \"'did\", 'think', 'little', 'dog', 'related', 'newman', 'christopher', 'johnson', 'bos', 'pleased', 'one', 'understood', 'badger', 'care', 'nocturnal', 'creature', 'day', 'live', 'large', 'family', 'group', 'burrow', 'ground', 'sett', 'cub', 'born', 'january', 'february', 'spend', 'month', 'underground', 'spring', 'little', 'warmer', 'statement', 'rspca', \"'this\", 'normal', 'behaviour', 'badger', 'nocturnal', 'would', 'open', 'daylight', 'amongst', 'people', \"'the\", 'rspca', 'would', 'advise', 'anyone', 'see', 'badger', 'behaving', 'like', 'distance', 'dog', \"'it\", 'may', 'unpredictable', 'aggressive', \"'if\", 'badger', 'concern', 'please', 'call', 'rspca', 'emergency', 'line']\n"
     ]
    }
   ],
   "source": [
    "print(data_df['text'][0])\n",
    "print(data_df['processed'][0])\n",
    "print(data_df['tokenized'][0])\n",
    "print(data_df['filtered'][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "08678a8541f14a85fadc7dc4a91337bf2218a82243f69853bfad973764afac67"
  },
  "kernelspec": {
   "display_name": "cours",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
